import os
from datetime import datetime
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù„Ù…ÙØªØ§Ø­
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© OPENAI_API_KEY")

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
with open("data/company_info_ar.txt", "r", encoding="utf-8") as f:
    ar_text = f.read().splitlines()

with open("data/company_info_en.txt", "r", encoding="utf-8") as f:
    en_text = f.read().splitlines()

# Ø¥Ù†Ø´Ø§Ø¡ embeddings Ù„ÙƒÙ„ Ù„ØºØ©
emb = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
vectordb_ar = FAISS.from_texts(ar_text, emb)
vectordb_en = FAISS.from_texts(en_text, emb)

retriever_ar = vectordb_ar.as_retriever()
retriever_en = vectordb_en.as_retriever()

# Ø³Ù„Ø³Ù„Ø© Ø³Ø¤Ø§Ù„/Ø¬ÙˆØ§Ø¨
qa_ar = RetrievalQA.from_chain_type(
    llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0),
    retriever=retriever_ar
)
qa_en = RetrievalQA.from_chain_type(
    llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0),
    retriever=retriever_en
)

print("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø±ÙƒØ© Ø¬Ø§Ù‡Ø². Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ (Ø£Ùˆ 'Ø®Ø±ÙˆØ¬' Ù„Ø¥Ù†Ù‡Ø§Ø¡):")

log_file = "chat_history.txt"

while True:
    query = input("Ø³: ")
    if query.strip().lower() in ["Ø®Ø±ÙˆØ¬", "exit", "quit"]:
        print("ğŸšª ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©.")
        break

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ©
    if any('\u0600' <= c <= '\u06FF' for c in query):
        answer = qa_ar.run(query)
        lang = "AR"
    else:
        answer = qa_en.run(query)
        lang = "EN"

    print("Ø¬:", answer)

    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ù…Ø¹ Ø§Ù„Ù„ØºØ©
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] ({lang})\nØ³: {query}\nØ¬: {answer}\n\n")
