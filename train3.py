import streamlit as st
import pandas as pd
import time
import os
from transformers import pipeline

# ---------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø©
# ---------------------------
st.set_page_config(page_title="AI Assistant", layout="wide")

DATA_FILE = "trained_data.csv"

# ---------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ---------------------------
def load_data():
    if os.path.exists(DATA_FILE):
        return pd.read_csv(DATA_FILE)
    else:
        return pd.DataFrame(columns=["question", "answer"])

def save_data(df):
    df.to_csv(DATA_FILE, index=False)

# ---------------------------
# Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø§Ù… (LLM)
# ---------------------------
qa_model = pipeline("text2text-generation", model="google/flan-t5-small")

def ai_answer(prompt):
    response = qa_model(prompt, max_length=200, do_sample=True)
    return response[0]["generated_text"]

# ---------------------------
# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ---------------------------
def train_on_data(uploaded_file):
    df = load_data()
    new_data = pd.read_csv(uploaded_file)

    progress = st.progress(0)
    status = st.empty()

    for i in range(0, len(new_data), 10):  # ØªÙ‚Ø³ÙŠÙ… Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (batch size = 10)
        batch = new_data.iloc[i:i+10]
        df = pd.concat([df, batch], ignore_index=True)
        save_data(df)

        progress.progress(min((i+10)/len(new_data), 1.0))
        status.text(f"ğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© {i+10 if i+10 < len(new_data) else len(new_data)} / {len(new_data)} ØµÙÙˆÙ ...")
        time.sleep(0.3)

    status.text("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.success("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­!")

# ---------------------------
# Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
# ---------------------------
def search_in_data(user_input, df):
    matches = df[df['question'].str.contains(user_input, case=False, na=False)]
    if not matches.empty:
        return matches.iloc[0]['answer']
    return None

# ---------------------------
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
# ---------------------------
tabs = st.tabs(["ğŸ“‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ› ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©"])

# ---------------------------
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# ---------------------------
with tabs[0]:
    st.header("ğŸ“‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ (question, answer)", type=["csv"])

    if uploaded_file:
        if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
            train_on_data(uploaded_file)

# ---------------------------
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ---------------------------
with tabs[1]:
    st.header("ğŸ› ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    df = load_data()
    st.dataframe(df)

    if st.button("ğŸ—‘ï¸ Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        save_data(pd.DataFrame(columns=["question", "answer"]))
        st.warning("ØªÙ… Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")

# ---------------------------
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
# ---------------------------
with tabs[2]:
    st.header("ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    user_input = st.text_input("ğŸ“ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

    if st.button("Ø¥Ø±Ø³Ø§Ù„"):
        df = load_data()
        answer = search_in_data(user_input, df)

        if answer:
            final_answer = answer
        else:
            final_answer = ai_answer(user_input)

        st.session_state.chat_history.append(("ğŸ‘¤", user_input))
        st.session_state.chat_history.append(("ğŸ¤–", final_answer))

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    for sender, msg in st.session_state.chat_history:
        st.write(f"**{sender}:** {msg}")
